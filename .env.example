# Server Configuration
PORT=3000

# CORS Configuration
ALLOWED_ORIGIN=http://localhost:5173

# LLM Provider Configuration
# Supported providers: "openai" or "gemini"
PROVIDER=your provider

# Model Configuration
# For OpenAI: gpt-4o-mini, gpt-4o, gpt-3.5-turbo
# For Gemini: gemini-2.5-flash, gemini-2.5-pro, gemini-1.5-flash, gemini-1.5-pro
MODEL_NAME=Your model

# API Keys
# REQUIRED: Set your API key based on the provider you're using
# For OpenAI: Get from https://platform.openai.com/api-keys (starts with sk-)
# For Gemini: Get from https://aistudio.google.com/app/apikey (starts with AIza)
MODEL_API_KEY=your API key